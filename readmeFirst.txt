开发环境:Eclipse ,语言:JAVA
主要依赖包:ansj_seg-5.0.1-all-in-one.jar,gson-2.2.4.jar
训练数据:opendata.txt   测试数据:opendata_20w
中间结果: content(训练数据内容)        entity(训练数据实体)   RuleBiLen2.txt(测试数据实体)  
输出结果:OutPutJsonRuleBiLen2.txt(输出数据文件)

主要代码文件:
/submit/SegTrain.java  用于分割文件,将训练数据的content 和 entity分为两个文件存储(见/submit/content.txt,/submit/entity.txt)
/submit/NerByAnsj.java  依赖ansj_seg-5.0.1-all-in-one.jar,用于识别测试集实体,主要简单的采用正则表达式
/submit/Obj.java,/submit/Object2Json.java  主要用于生成赛题要求的标准输出数据格式,依赖gson-2.2.4.jar



下面是赛题的简单思路:
一,根据训练数据集,将数据文件进行分割,得到文本内容content.txt文件和标准答案json.txt文件.文件均以unicode编码
具体分割文件的代码可参见:SegTrain.java,得到的文本文件见附件:content.txt和json.txt.
二,分别对这两个文件进行处理:由json.txt文件得到文本内容的答案集合,该集合中涉及的实体,通过统计实体的类型,主要有以下几类:
人名,地名,机构名,职位名,公司名,产品名(书名号包括的视为产品名).根据json.txt统计得到的结果,对训练文本content.txt进行解析和算法选择训练
三,根据二,可以先观察content.txt文件,通过观察文件,可以发现基于规则的方法,基于正则表达式,就可以得到大量的实体.比如:书名号代表的产品名,句子开头"的"/"是"之前的短长度主体(名词/短语等).当然这些是比较显而易见的.再者,需要借助机器学习的方法,对文本进行命名实体识别.可以通过调用API(比如LTP语言云/bosonnlp等),也可以借助开源项目比如ansj/jieba/hanlp等,也可以基于CRF++等开源工具,当然也可以自己设计.这里我们就任意选择了一个ansj作分词,然后词性标注后,识别实体.
四,线下测试,编写评分脚本,用于评估模型的质量,线上测试,不断调整模型.


key1,key2为固定字符串;
value1 = "N行文本中的一行"
value2 = "多个字符串"
形式如下:
[{"key1": "value1", "key2": ["value2"]}]

比如:[{"yes":"这个问题我没有搞定","no":["问题","没有","搞定"]}]
Java下常见的Json类库有Gson、JSON-lib、fastjson和Jackson等，我主要这里采用的是Gson(见附件gson-2.2.4.jar),实现json格式的数据与java之间的转换.想要达到的效果是:
输入:key1 value1和key2 value2,输出: [{"key1": "value1", "key2": ["value2"]}]
以及其反向操作.
关于json数据格式到java对象之间的转换,以及java对象到json格式的构建,
主要采用gson的toJson方法和fromJson方法
可参见代码:Obj.java(对象文件),Json2Object.java(json格式数据转对象),Object2Json.java(对象转Json格式数据)


命名实体识别:(当然这个赛体,不止是一个实体识别问题,由于在准备校招的事情,投入的时间不多.也就简化了求解)

一般来说，命名实体识别的任务就是识别出待处理文本中三大类（实体类、时间类和数字类）、七小类（人名、机构名、地名、时间、日期、货币和百分比）命名实体。NER的主要研究内容分为两个部分：（1）实体边界识别；（2） 确定实体类别（人名、地名、机构名或其他）。
总结NER的难点：
（1）汉语文本没有类似英文文本中空格之类的显式标示词的边界标示符，命名实体识别的第一步就是确定词的边界，即分词；
（2）汉语分词和命名实体识别互相影响；
 (3)现代汉语文本，尤其是网络汉语文本，常出现中英文交替使用，这时汉语命名实体识别的任务还包括识别其中的英文命名实体；
 (4)不同的命名实体具有不同的内部特征，不可能用一个统一的模型来刻画所有的实体内部特征。
 (5)除了英语中定义的实体，外国人名译名和地名译名是存在于汉语中的两类特殊实体类型；

在命名实体识别上,我们首先基于词性标注的方法,首先对给定语料进行词性标注,标注过程中,对人名/地名/机构名进行识别,这里基于Ansj的词性标注的思想给句子进行了词性标注.进行了人名地名机构名识别,从成分句法分析的角度,对句子的主语进行识别,也即类似"是"之前的短语的识别,再者从词性分类的角度进行学习,构建分类器,构建核心实体词性和句子词性之间的关系模型.

对opendata_20W的书名数据进行统计,并输出其最大长度,以便于在给定文本长度规则的限值下使用
经过检测(JianCeJuHaoCount.java),测试数据中opendata_20w的数据中,以句号分割,每一单行,都没有别的子句,也即所有文本都是单句,这里作为单句处理.



